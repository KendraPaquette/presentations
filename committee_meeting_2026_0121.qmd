---
title: "Kendra's Committee Meeting"
author: "Kendra Wyant"
date: "January 21, 2026"
institute: "University of Wisconsin-Madison"
format: 
  revealjs:
    css: slides.css
    incremental: false  
    auto-stretch: false
    logo: images/arc_logo.png
    footer: "Committee Meeting"
slide-number: false
editor_options: 
  chunk_output_type: console
title-slide-attributes:
  data-background-image: images/title_slide.png
  data-background-size: cover
  data-background-repeat: no
  data-background-position: right top
---

## Agenda

1.  Updates since April

2.  Plan for remaining timeline

3.  Dissertation progress

## Updates: Clinical

Practicum at Mendota Mental Health Institue

Internship Applications

## Updates: Research Products

Chaired Symposium

Publication

2 more papers under review

## Timeline

Covariate selection paper

Burden paper

Accepted poster presentation at Optimization Intervention Conference

Invited for APS symposium (waiting to hear if accepted)

Defend Dissertation in late April or early May

## Dissertation Progress

4 Studies:

1.  Predict and characterize *immediate* alcohol lapse risk (i.e., in the next week, day, or hour) using machine learning methods.

2.  Predict and characterize *future* alcohol lapse risk (i.e., 1 day, 3 days, 1 week or 2 weeks in the future) using machine learning methods.

3.  Predict and characterize *immediate* (next-day) opioid lapse risk from geolocation and daily surveys using machine learning methods.

4.  Predict and characterize *immediate* (next-day) and *future* (next two weeks and next month) opioid lapse risk from geolocation and daily surveys using individual state-space models.

## Study 3: Participants

- 451 participants recruited from 47 states in the United States
- 336 were eligible, consented, and remained on study for at least one month
- 299 participants in final sample

    - 11 participants were excluded due to unusually low adherence to EMA or geolocation sensing
    - 13 participants were excluded due to insufficient context data for geolocation points (<2 locations outside home)
    - 1 participant was excluded due to geolocation data indicating they were not residing in the United States
    - 11 participants were excluded due to evidence of careless responding on EMAs and/or no longer having a goal of abstinence 

## Study 3: Participants

- Mean days on study across participants: 297 days (range 32-395)
- 83% of participants remained on study for at least 6 months
- On average, participants completed 73% of daily EMA prompts (range 24-100%)
- On average, participants provided 311 daily geolocation points (range 20-825)


## Study 3: Features 

- 674 features 

    1. Individual differences in demographic and OUD characteristics
    2. Day of the start of the prediction window
    3. Dynamic EMA and geolocation sensing data
    
    
- Full model = feature sets 1-3
- Baseline model = features sets 1 and 2

:::{.notes}
All features (sets 1-3 above) were included in our full model. We also fit a baseline model that excluded the dynamic EMA and geolocation features (i.e., only using feature sets 1 and 2 above) to assess the incremental predictive value of these sensing features.
:::


## Study 3: Labels

- Prediction windows start at 6:00 am in participants' local timezones and end at 5:59 am the next day

:::{.notes}
Participants reported lapses on the first EMA item. If participants responded “yes” to the question “Have you used any opioids for non-medical reasons that you have not yet reported?”, they were prompted to select the day(s) and time(s) of the lapse(s). Times were reported in 6-hour increments (12:00am–5:59am, 6:00am–11:59am, 12:00pm–5:59pm, 6:00pm–11:59pm). These responses were used to label each prediction window as lapse or no lapse. 
:::

## Study 3: Performance
6 x 5 cross-validation

Evaluate on: 

1. Discrimination

2. Calibration

3. Overall Performance

Don't evaluate classification and clinical utility (but open to hearing alternative perspectives on this decision).

:::{.notes}
All participants data was either in held in or held out test set to avoid introducing bias.

Fit: elastic net,  XGBoost, 
Plan to also look at: random forest, a single-layer neural network, and a support vector machine

We evaluate the best full model’s probability predictions across three domains: discrimination, calibration, and overall performance.  Classification and clinical utility are two other important domains for evaluating a model intended to make or inform a decision (e.g., whether to send a support message to an individual). In our scenario there is no decision to be made. Hypothetically, every day an individual would receive a message regardless of lapse risk, equivalent to a treat all condition. Therefore, we have constrained our evaluation to focus on the probability estimates for evaluating performance.
:::

## Study 3: Discrimination


Full model auROC = 0.93 95% CI [0.92, 0.94]

Baseline model auROC = .74 95% CI [0.71, 0.77]

Probability full model performed better = 1.0

:::{.notes}
Our performance metric for model selection and evaluation was the area under the receiver operating characteristic curve (auROC)

auROC is an aggregate measure of discrimination across all possible decision thresholds. This is important because optimal thresholds depend on the setting, outcome prevalence, and the relative costs of misclassification, and should be addressed separately (e.g., with a decision curve analysis).

We used a Bayesian hierarchical generalized linear model to estimate the posterior distribution and 95% credible intervals (CI) for auROC for the 30 held-out test sets for our best full and baseline models. 

Dem: Ordinal features for age, education, and income based on predefined response ranges, an ordinal feature for RUCA code associated with home address (range 1-10), and dummy coded features for gender (male vs. not male) and race and ethnicity (non-Hispanic White vs. Hispanic and/or not White). 

OUD characteristics: we created ordinal features for recovery satisfaction, recovery motivation, recovery confidence, MOUD side effects experienced, perceived efficacy of MOUD medication, and likelihood of continuing MOUD (ranges 0-4), ordinal features for frequency of counseling sessions and self-help meetings attended in the past month (ranges 0-3), a quantitative feature for number of self-reported DSM-5 OUD symptoms, an ordinal feature for lifetime history of overdose (range 0-4), and dummy coded features for past month opioid use (yes vs. no), past month detox or residential treatment (yes vs. no), past month psychiatric medication (yes vs. no), preferred opioid (fentanyl vs. heroin vs. prescription opioid not for opioid treatment vs. medication for opioid treatment), and preferred route of administration (injection vs. oral vs. smoke vs. sniff/snort vs. other).
:::

## Study 3: Calibration and Overall Performance

:::{.column width = "20%"}

:::

:::{.column width = "60%"}

![](https://github.com/KendraPaquette/presentations/blob/main/figs/performance.png?raw=true)
:::

:::{.column width = "20%"}
:::


:::{.notes}
The left panel presents a calibration plot of raw and Platt scaled risk probabilities. Predicted probabilities (x-axis) are binned into deciles. Observed lapse probability (y-axis) represents the proportion of actual lapses observed in each bin. The dashed diagonal represents perfect calibration. Points below the line indicate overestimation and points above the line indicate underestimation. Raw probabilities are depicted as the dark purple line. Platt calibrated probabilities are depicted as the green dashed line. The rug plot along the x-axis depicts observation frequency in each bin. The right panel presents histograms of raw (uncalibrated) risk probability distributions separately by true lapse outcome.
:::

## Study 3: Fairness

:::{.column width = "20%"}
:::

:::{.column width = "60%"}
![](https://github.com/KendraPaquette/presentations/blob/main/figs/fairness.png?raw=true){.absolute height="80%"}
:::

:::{.column width = "20%"}
:::


:::{.notes}
We performed five dichotomous subgroup analyses to assess the fairness of our model’s predictions. Using the same 30 held-out test sets and the same modeling procedure as above, we calculated the median posterior probability and 95% CI for auROC for each model separately by gender (not male vs. male), race/ethnicity (Hispanic and/or non-White vs. non-Hispanic White), income (below poverty line vs. above poverty line), geographic location (rural vs. urban)1, and education (high school or less vs. some college). We conducted Bayesian group comparisons to assess the likelihood that each model performs differently by group.

Our fairness subgroup comparisons for the full model revealed no evidence that performance meaningfully differed by education (probability = 0.55) and strong evidence that performance differed by gender, income, race and ethnicity, and geographic location (probabilities > 0.90). Notably, our model performed better for individuals with an annual income below the federal poverty line compared to individuals above the federal poverty line, thus favoring the disadvantaged group. While differences in performance estimates exist across subgroups, they are not likely clinically meaningful as all of our subgroups yielded median auROCs between 0.91 - 0.94
:::

## Study 3: Feature Importance

:::{.column width = "15%"}
:::

:::{.column width = "70%"}

![](https://github.com/KendraPaquette/presentations/blob/main/figs/feature_importance_1.png?raw=true)
:::

:::{.column width = "15%"}
:::


## Study 3: Feature Importance

:::{.column width = "15%"}
:::

:::{.column width = "70%"}
![](https://github.com/KendraPaquette/presentations/blob/main/figs/feature_importance_2.png?raw=true)
:::

:::{.column width = "15%"}
:::


## Proposed Change of Scope

Move study 4 outside scope of dissertation. 

1.  Predict and characterize *immediate* alcohol lapse risk (i.e., in the next week, day, or hour) using machine learning methods.

2.  Predict and characterize *future* alcohol lapse risk (i.e., 1 day, 3 days, 1 week or 2 weeks in the future) using machine learning methods.

3.  Predict and characterize *immediate* (next-day) opioid lapse risk from geolocation and daily surveys using machine learning methods.


