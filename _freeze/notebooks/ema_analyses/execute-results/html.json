{
  "hash": "c0600b308524f98d9b559032022d1f4a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: EMA Analyses\nauthor: Kendra Wyant\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#|echo: FALSE\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"77e91675366f10788c6bcb59fa1cfc9ee0c75281\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntidymodels_conflictRules()\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidyposterior)\ntheme_set(theme_classic())\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: FALSE\n#| output: False\n\npath_processed <- format_path(\"studydata/risk/data_processed/ema\")\npath_models <- format_path(\"studydata/risk/models/ema\")\npath_shared <- format_path(\"studydata/risk/data_processed/shared\")\n\nauc_week <- read_rds(file.path(path_models, \"outer_metrics_1week_0_v5_nested_main.rds\")) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_day <- read_rds(file.path(path_models, \"outer_metrics_1day_0_v5_nested_main.rds\")) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_hour <- read_rds(file.path(path_models, \"outer_metrics_1hour_0_v5_nested_main.rds\")) |> \n  arrange(outer_split_num) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\n\nauc <- auc_week |> \n  rename(week = roc_auc) |> \n  mutate(day = auc_day$roc_auc,\n         hour = auc_hour$roc_auc) \n\nauc_week_baseline <- read_rds(file.path(path_models, \"outer_metrics_1week_0_v3_nested_baseline.rds\")) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_day_baseline <- read_rds(file.path(path_models, \"outer_metrics_1day_0_v3_nested_baseline.rds\")) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_hour_baseline <- read_rds(file.path(path_models, \"outer_metrics_1hour_0_v3_nested_baseline.rds\")) |> \n  mutate(repeat_num = rep(str_c(\"repeat\", 1:3), each = 10),\n         fold_num = rep(str_c(\"fold\", 1:10),3)) |>   # assumes 3x10 fold\n  select(repeat_num, fold_num, roc_auc)\n\nauc_baseline <- auc_week_baseline |> \n  rename(week_baseline = roc_auc) |> \n  mutate(day_baseline = auc_day_baseline$roc_auc,\n         hour_baseline = auc_hour_baseline$roc_auc) |> \n  full_join(auc, by = c(\"repeat_num\", \"fold_num\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n#| output: false\n\nset.seed(101)\npp <- auc |> \n  rename(id = repeat_num,\n         id2 = fold_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n           transform = tidyposterior::logit_trans,  \n           iter = 2000, chains = 4,  \n           adapt_delta = .99,\n           family = gaussian) \n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.5e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.55 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.351 seconds (Warm-up)\nChain 1:                1.076 seconds (Sampling)\nChain 1:                2.427 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.755 seconds (Warm-up)\nChain 2:                0.904 seconds (Sampling)\nChain 2:                2.659 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.3e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.934 seconds (Warm-up)\nChain 3:                0.953 seconds (Sampling)\nChain 3:                2.887 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.3e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.942 seconds (Warm-up)\nChain 4:                1.101 seconds (Sampling)\nChain 4:                3.043 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| echo: false\n#| output: false\n\npp_tidy <- pp |> \n  tidy(seed = 123)\n\nci <- pp_tidy |> \n  summary() |> \n  mutate(model = factor(model, levels = c(\"week\", \"day\", \"hour\")),\n         y = 1000)\n```\n:::\n\n\n### Posteriors\n\n\n::: {#cell-fig-ema-posteriors .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-ema-posteriors\n#| fig-cap: \"Caption\"\n\npp_tidy |> \n  mutate(model = factor(model, levels = c(\"week\", \"day\", \"hour\"))) |>\n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,\n                           color = model),\n               data = ci) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper, color = model),\n                data = ci) +\n  facet_wrap(~model, ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", breaks = c(0, 500, 1000)) +\n  # ylab(\"Posterior Probability Density\") +\n  xlab(\"Area Under ROC Curve\")  +\n  theme(legend.position = \"none\")\n  # geom_text(aes(c(\"Median = 0.90\", \"Median = 0.91\", \"Median = .93\")))\n```\n\n::: {.cell-output-display}\n![Caption](ema_analyses_files/figure-html/fig-ema-posteriors-1.png){#fig-ema-posteriors width=672}\n:::\n:::\n\n\n\n### Model Contrasts\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nci <- pp |> \n  contrast_models(list(\"hour\",\"hour\", \"day\"), \n                list(\"week\", \"day\", \"week\")) |> \n  summary(size = .01) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"hour vs week\", \"hour vs day\", \"day vs week\"),\n                           labels = c(\"Hour vs. Week\", \"Hour vs. Day\", \"Day vs. Week\")),\n         y = 850)\n```\n:::\n\n::: {#cell-fig-ema-contrasts .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-ema-contrasts\n#| fig-cap: \"Caption\"\n\npp |> \n  tidy(seed = 123) |>   \n  group_by(model) |> \n  mutate(sample = row_number()) |> \n  ungroup() |> \n  pivot_wider(names_from = model, values_from = posterior) |> \n  mutate(hour_vs_week = hour - week,\n         hour_vs_day = hour - day,\n         day_vs_week = day - week) |> \n  pivot_longer(cols = hour_vs_week:day_vs_week,\n               names_to = \"contrast\",\n               values_to = \"posterior\") |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"hour_vs_week\", \"hour_vs_day\", \"day_vs_week\"),\n                           labels = c(\"Hour vs. Week\", \"Hour vs. Day\", \"Day vs. Week\"))) |> \n  ggplot() +\n  geom_histogram(aes(x = posterior), \n                 color = \"black\", fill = \"grey\", alpha = .4, bins = 30) +\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\") +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean), \n               data = ci, show.legend = FALSE) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper), \n               data = ci, show.legend = FALSE) +\n  # geom_text(data = ci, x = c(.0255, .043, .018), y = 700, \n  #           label = str_c(round(ci$mean, 2), \" [\", round(ci$lower, 2), \", \", round(ci$upper, 2), \"]\")) +\n  facet_wrap(~contrast, ncol = 1) +\n  xlab(\"auROC difference\") +\n  ylab(\"Count\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Caption](ema_analyses_files/figure-html/fig-ema-contrasts-1.png){#fig-ema-contrasts width=672}\n:::\n:::\n\n\n### Baseline Model Comparisons\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n#| output: false\n\nset.seed(101)\npp_baseline <- auc_baseline |> \n  rename(id = repeat_num,\n         id2 = fold_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n           transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n           iter = 2000, chains = 4,  \n           adapt_delta = .99,\n           family = gaussian) \n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 3.177 seconds (Warm-up)\nChain 1:                1.431 seconds (Sampling)\nChain 1:                4.608 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 2.925 seconds (Warm-up)\nChain 2:                1.411 seconds (Sampling)\nChain 2:                4.336 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 3.321 seconds (Warm-up)\nChain 3:                3.077 seconds (Sampling)\nChain 3:                6.398 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.8e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 3.172 seconds (Warm-up)\nChain 4:                1.497 seconds (Sampling)\nChain 4:                4.669 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| echo: false\n#| output: false\n\nci_baseline <- contrast_models(pp_baseline, \n                  list(\"hour\",\"day\", \"week\"), \n                  list(\"hour_baseline\", \"day_baseline\", \"week_baseline\")) |> \n  summary(size = .01) |> \n  mutate(contrast = factor(contrast,\n                           levels = c(\"week vs week_baseline\",\n                                      \"day vs day_baseline\",\n                                      \"hour vs hour_baseline\"),\n                           labels = c(\"Week vs. Week Baseline\",\n                                      \"Day vs. Day Baseline\",\n                                      \"Hour vs. Hour Baseline\")),\n         y = 1000)\n```\n:::\n\n::: {#cell-fig-ema-baseline .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-ema-baseline\n#| fig-cap: \"Caption\"\n\npp_baseline |>\n  tidy(seed = 123) |>\n  group_by(model) |>\n  mutate(sample = row_number()) |>\n  ungroup() |>\n  pivot_wider(names_from = model, values_from = posterior) |> \n  mutate(hour_vs_hour_baseline = hour - hour_baseline,\n         day_vs_day_baseline = day - day_baseline,\n         week_vs_week_baseline = week - week_baseline) |>\n  pivot_longer(cols = hour_vs_hour_baseline:week_vs_week_baseline,\n               names_to = \"contrast\",\n               values_to = \"posterior\") |> \n  mutate(contrast = factor(contrast,\n                           levels = c(\"week_vs_week_baseline\",\n                                      \"day_vs_day_baseline\",\n                                      \"hour_vs_hour_baseline\"),\n                           labels = c(\"Week vs. Week Baseline\",\n                                      \"Day vs. Day Baseline\",\n                                      \"Hour vs. Hour Baseline\"))) |> \n  ggplot() +\n  geom_histogram(aes(x = posterior), \n                 color = \"black\", fill = \"light grey\", \n                 alpha = .4, bins = 30, show.legend = FALSE) +\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\") +\n  geom_segment(mapping = aes(y = y+600, yend = y+200, x = mean, xend = mean),\n               data = ci_baseline, show.legend = FALSE) +\n  geom_segment(mapping = aes(y = y+400, yend = y+400, x = lower, xend = upper), \n               data = ci_baseline, show.legend = FALSE) +\n  facet_wrap(~contrast, ncol = 1) +\n  xlab(\"auROC difference\") +\n  ylab(\"Count\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Caption](ema_analyses_files/figure-html/fig-ema-baseline-1.png){#fig-ema-baseline width=672}\n:::\n:::\n",
    "supporting": [
      "ema_analyses_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}