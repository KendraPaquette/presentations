{
  "hash": "d694627f089fca64844d6064379426e0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: EMA Analyses\nauthor: Kendra Wyant\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#|echo: FALSE\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"77e91675366f10788c6bcb59fa1cfc9ee0c75281\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntidymodels_conflictRules()\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidyposterior)\ntheme_set(theme_classic())\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n:::\n\n\n### Posterior Probabilities\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nsim_auroc <- tibble(lag = rep(0, 10),\n                    repeat_num = rep(1, 10),\n                    fold_num = seq(1:10),\n                    auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .88, sd = .04)) |> \n  bind_rows(tibble(lag = rep(0, 10),\n                   repeat_num = rep(2, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .88, sd = .04))) |> \n   bind_rows(tibble(lag = rep(0, 10),\n                   repeat_num = rep(3, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .88, sd = .04))) |> \n   bind_rows(tibble(lag = rep(24, 10),\n                   repeat_num = rep(1, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .87, sd = .04))) |> \n   bind_rows(tibble(lag = rep(24, 10),\n                   repeat_num = rep(2, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0,mean = .87, sd = .04))) |> \n   bind_rows(tibble(lag = rep(24, 10),\n                   repeat_num = rep(3, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .87, sd = .04))) |> \n  bind_rows(tibble(lag = rep(72, 10),\n                   repeat_num = rep(1, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .85, sd = .04))) |> \n   bind_rows(tibble(lag = rep(72, 10),\n                   repeat_num = rep(2, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .85, sd = .04))) |> \n   bind_rows(tibble(lag = rep(72, 10),\n                   repeat_num = rep(3, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .85, sd = .04))) |> \n  bind_rows(tibble(lag = rep(168, 10),\n                   repeat_num = rep(1, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .82, sd = .04))) |> \n   bind_rows(tibble(lag = rep(168, 10),\n                   repeat_num = rep(2, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .82, sd = .04))) |> \n   bind_rows(tibble(lag = rep(168, 10),\n                   repeat_num = rep(3, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0,  mean = .82, sd = .04))) |> \n   bind_rows(tibble(lag = rep(336, 10),\n                   repeat_num = rep(1, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .78, sd = .04))) |> \n   bind_rows(tibble(lag = rep(336, 10),\n                   repeat_num = rep(2, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .78, sd = .04))) |> \n   bind_rows(tibble(lag = rep(336, 10),\n                   repeat_num = rep(3, 10),\n                   fold_num = seq(1:10),\n                   auroc = truncnorm::rtruncnorm(n = 10, b = 1.0, mean = .78, sd = .04)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\nset.seed(101)\npp <- sim_auroc |> \n  pivot_wider(names_from = lag, values_from = auroc) |> \n  rename(id = repeat_num,\n         id2 = fold_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n         transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n         adapt_delta = .99,\n         family = gaussian, \n)  \n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.58 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.243 seconds (Warm-up)\nChain 1:                0.564 seconds (Sampling)\nChain 1:                1.807 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.7e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.543 seconds (Warm-up)\nChain 2:                0.872 seconds (Sampling)\nChain 2:                2.415 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.6e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.7 seconds (Warm-up)\nChain 3:                0.825 seconds (Sampling)\nChain 3:                2.525 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.6e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.338 seconds (Warm-up)\nChain 4:                0.599 seconds (Sampling)\nChain 4:                1.937 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_tidy <- pp |> \n  tidy(seed = 123) \n\nci <- pp_tidy |> \n  summary() |> \n  mutate(model = factor(model, levels = c(0, 24, 72, 168, 336),\n                        labels = c(\"0 lag\", \"24 lag\", \"72 lag\", \"168 lag\", \"336 lag\")),\n         y = 1000)\n```\n:::\n\n::: {#cell-fig-lag-posteriors .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-lag-posteriors\n\npp_tidy |> \n  mutate(model = factor(model, levels = c(0, 24, 72, 168, 336),\n                        labels = c(\"0 lag\", \"24 lag\", \"72 lag\", \"168 lag\", \"336 lag\"))) |>\n  ggplot() + \n  geom_histogram(aes(x = posterior, fill = model), color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean,\n                           color = model),\n               data = ci) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper, color = model),\n                data = ci) +\n  facet_wrap(~model, ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", breaks = c(0, 500, 1000)) +\n  xlab(\"Area Under ROC Curve\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](lag_analyses_files/figure-html/fig-lag-posteriors-1.png){#fig-lag-posteriors width=672}\n:::\n:::\n\n\n\n### Model Contrasts\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci <- pp |>\n  contrast_models(list(\"0\", \"24\", \"72\", \"168\"), \n                  list(\"24\", \"72\", \"168\", \"336\")) |> \n  summary(size = .01) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"0 vs 24\", \"24 vs 72\", \"72 vs 168\", \"168 vs 336\")),\n         y = 700)\n```\n:::\n\n::: {#cell-fig-lag-contrasts .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-lag-contrasts\n\npp |> \n  tidy(seed = 123) |>   \n  group_by(model) |> \n  mutate(sample = row_number()) |> \n  ungroup() |> \n  pivot_wider(names_from = model, values_from = posterior) |> \n  mutate(`0 vs 24` = `0` - `24`,\n         `24 vs 72` = `24` - `72`,\n         `72 vs 168` = `72` - `168`,\n         `168 vs 336` = `168` - `336`) |> \n  pivot_longer(cols = `0 vs 24`:`168 vs 336`,\n               names_to = \"contrast\",\n               values_to = \"posterior\") |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"0 vs 24\", \n                                      \"24 vs 72\", \n                                      \"72 vs 168\",\n                                      \"168 vs 336\"))) |> \n  ggplot() +\n  geom_histogram(aes(x = posterior), \n                 color = \"black\", fill = \"grey\", \n                 alpha = .4, bins = 30) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  geom_segment(mapping = aes(y = y+100, yend = y-100, x = mean, xend = mean), data = ci) +\n  geom_segment(mapping = aes(y = y, yend = y, x = lower, xend = upper), data = ci) +\n  facet_wrap(~contrast, ncol = 1) +\n  ylab(\"Posterior Probability\") +\n  xlab(\"Model Contrast for AUC\") +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](lag_analyses_files/figure-html/fig-lag-contrasts-1.png){#fig-lag-contrasts width=672}\n:::\n:::",
    "supporting": [
      "lag_analyses_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}