---
title: "Lagged predictions of next day alcohol use for personalized continuing care support"
subtitle: "Kendra Wyant"
author: "Gaylen Fronk, Jiachen Yu, John J. Curtin"
date: "April 3, 2025"
institute: "University of Wisconsin-Madison"
format: 
  revealjs:
    css: slides.css
    incremental: false  
    logo: arc_logo.png
    footer: "Collaborative Perspectives on Addiction 2025"
slide-number: false
editor_options: 
  chunk_output_type: console
---


## Alcohol Use Disorder

::: {.columns}

:::{.column width = "70%"}

- Chronic disease

:::{.fragment}
- Continuing care for ongoing monitoring and early reintervention
:::

:::{.fragment}
- Alcohol use disorder treatment is lacking
:::
:::

:::{.column width = "30%"}

![](https://github.com/KendraPaquette/presentations/blob/main/images/crowd.png?raw=true){.absolute top=0 right=0 height=100%}
:::
:::

::: {.notes}
Alcohol use disorder is a chronic disease, characterized by high relapse rates, frequent reentry into treatment, and an increased risk of mortality.

Continuing care, including ongoing monitoring and early re-intervention, has been well established as the gold standard for managing chronic health conditions such as diabetes, asthma, and HIV. 

When it come to AUD we generally do not treat it very well. We have treatments that work, but few individuals receive them. Additionally, substance use treatment is most effective when care is prescribed over longer durations and involves active efforts to keep patients engaged. But those that do receive treatment often receive time-limited care focused on initial symptom reduction.
:::


## Continuing Care

::: {.columns}

:::{.column width = "50%"}
{{< embed ../notebooks/treatment_figure.qmd#samhsa >}}

<span style="font-size: 20px; margin-left: 20px;">SAMHSA 2022</span>
:::

:::{.column width = "50%"}
:::{.fragment}
Barriers:

- Cost and insurance reimbursement issues
- Lack of collaborative provider teams
- Passive referral processes
- Geographic barriers 
- Patient dropout
- Changes in clinical needs over time

<span style="font-size: 20px; margin-left: 40px">Dennis and Scott 2007; Tai and Volkow 2013; McKay 2021</span>
:::
:::

:::

::: {.notes}
To illustrate, of the almost 30 million US adults with an active AUD in 2022, it is estimated that about 12% received any treatment.
We do not have data to know how many people receive long term support or continuing care after initial treatment, but given these numbers we can imagine it is much lower.

Especially considering the many well documented barriers including cost and insurance reimbursement issues, lack of collaborative provider teams, passive referral processes, geographic barriers to accessing services, patient dropout, and changes in the patient’s clinical needs over time. This leaves a large treatment gap when it comes to long-term continuing care for alcohol use disorder.
:::

## Relapse Prevention

- Relapses can occur at any point in recovery

::: {.fragment}
- Risk factors are individualized, dynamic, and interactive
:::

::: {.fragment}
- Optimal supports to address risk factors vary across individuals and within an individual over time
:::

:::{.notes}
Continuing care for relapse prevention is an important part of recovery.

Relapses can occur at any point, even after years of successful moderation or abstinence.

The risk factors preceding relapse during recovery are individualized, numerous, dynamic and interactive.

Therefore, the optimal supports to address these risk factors vary both across individuals and within an individual over time. In other words, different people will need different supports at different times.

Personalized risk monitoring could help patients adapt their lifestyles, behaviors, and supports to their changing needs.

But we don’t have the resources for long-term continuous clinician care and self-monitoring is really hard!
:::



## Recovery Monitoring and Support System

::: {.columns}
:::{.column width = "50%"}

::: {.fragment}
- Highly scalable
:::

:::{.fragment}
- Personalized adaptive recommendations
:::

:::{.fragment}
- Prompt individuals to engage with support at times of high risk
:::
:::



:::{.column width = "50%"}
:::{.fragment}
![](https://github.com/KendraPaquette/presentations/blob/main/images/sensingsystem.png?raw=true)
:::
:::
:::

:::{.notes}
An algorithm-guided recovery monitoring and support system could help patients self-monitor their risk for relapse.

This system could provide a scalable option for low-cost, long-term monitoring; offer personalized, adaptive recommendations aligned with evidenced-based care; and prompt individuals to engage with support at times of high risk.

For example individuals could receive daily messages about changes in their relapse risk and receive personalized recommendations based on top features contributing to their risk. Like an urge surfing recommendation for someone with strong cravings.

For such a system to exist, we need two things. 
One, the system must be able to collect a rich and densely sampled source (or sources) of risk-relevant data.

Two, the system must have access to a model that can predict alcohol use with high performance and have interpretable model inputs for support recommendations to be mapped onto. 
:::



## Machine Learning and Digital Data

::: {.fragment}
- High dimensional feature sets
:::

::: {.fragment}
- Non-linear and interactive relationships between features and lapse risk probability
:::

:::{.fragment}
- Interpretability of feature importance
:::

:::{.notes}

Advances in both smartphone sensing of digital data and machine learning now make this possible. Smartphone sensing approaches (e.g., ecological momentary assessment, geolocation sensing) can provide the frequent, longitudinal measurement of proximal risk factors necessary for precise prediction.

Machine learning models can handle high dimensional feature sets. They can accommodate non-linear and interactive relationships between features and lapse risk probability. Additionally, methods from interpretable machine learning can be used to understand which risk features contribute most strongly to a lapse prediction.

:::


## Ecological Momentary Assessment

:::{.columns}
:::{.column width = "60%"}
- Direct and frequent insight into subjective feelings and experiences

:::{.fragment}
- Constructs easily map onto well-studied risk factors for lapse
:::

:::{.fragment}
- Appears to be well-tolerated
:::

:::


:::{.column width = "40%"}
![](https://github.com/KendraPaquette/presentations/blob/main/images/ema.png?raw=true){.absolute top=0 right=0 height=100%}
:::
:::

:::{.notes}
EMA may be one promising sensing method for lapse prediction.

It offers direct and frequent insight into subjective feelings and experiences that can be easily mapped onto modular forms of treatment like the relapse prevention model 

Furthermore, individuals with SUDs have found EMA to be acceptable for sustained measurement for up to a year with relatively high compliance, suggesting that this method is feasible for long-term monitoring throughout recovery.

:::

## Study Goals

Use EMA to:

1. Predict immediate lapses back to alcohol use (i.e., next 24 hours)

:::{.fragment}
2. Predict lapses occuring in a 24 hour window 2 weeks from now
:::

:::{.notes}
In this study we use ema to predict immediate lapses back to alcohol use (i.e., next 24 hours).

This model could be updated daily to provide individuals information about changes in their risk and make supportive recommendations for immediate action based on the top features. 

Earlier I gave the example of an urge surfing recommendation for someone with strong cravings. This could also include recommending a guided relaxation video when someone is reporting recent stressful events or offering encouragement when someone has gone a certain length of time without drinking.

Importantly, this assumes that the recommendations can be implemented immediately, likely in a smartphone app.

But the best recommendation might not be able to be done immediately. Imagine trying to schedule a therapy appointment in the next 24 hours!

Therefore, in this project we also built a model that shifted the 24 hour prediction window 2-weeks into the future. So essentially this model predicts the probability that someone will lapse in a 24 hour window two weeks from now.

These “time-lagged” predictions could give people advanced warning to implement supports not immediately available to them.

:::

## Design

- 3-month longitudinal study
- Participants completed 4 surveys daily
    - craving, arousal, valence, stressful events, risky situations, pleasant events, efficacy, alcohol use
    
:::{.fragment}
- 279 features
- Outcome = lapse or no lapse
- XGBoost algorithm
- Grouped nested k-fold cross-validation
:::


::: {.notes}
Participants completed 4 daily surveys for up to three months

Each survey had 10 items that asked about 
The greatest intensity of craving, arousal, and valence since the last survey.  

Stressful events, risky situations and pleasant events encountered since their last survey

Future stressful events, risky situations and efficacy looking in the next week

And any alcohol use they had not yet reported.

We used all 10 EMA items plus 7 demographic questions to engineer our features. We had a total of 279 features. 
Time and day of alcohol use to generate our outcome labels of lapse or no lapse.
We considered a range of statistical algorithms, but XGBoost consistently emerged as our best model in validation sets so for evaluation we only considered XGBoost.
We used grouped nested k-fold cross-validation to ensure our models were evaluated on new data from new individuals
:::

## Participants


:::{.notes}
Our sample consisted of 151 participants with moderate to severe alcohol use disorder living in the Madison, WI area.

Our sample was predominantly non-Hispanic White with personal incomes above the 2024 federal poverty line. We had equal representation of men and women and the average age was 41 years.

All of our participants had a goal of abstinence which made it easier for us to identify discrete lapse onsets.
:::

## Adherence

:::{.columns}
:::{.column width = "50%"}
{{< embed ../notebooks/burden_analyses.qmd#compliance >}}
:::

:::{.column width = "50%"}
- 3.1 of 4 surveys completed daily (78.4% compliance)
- 95% compliance for completing at least one survey daily
:::
:::

:::{.notes}
Participants on average completed 3.1 of the four EMAs each day (78.4% compliance overall). Participants completed at least one EMA on 95.0% of days. 

The plot on the left shows the percentage of EMA completion looking at the full 4x daily protocol (in red) and completion of at least 1x daily EMA (in grey) over the number of weeks on study. We found participants on average were able to sustain EMA adherence over the full three months.
:::

## Model Performance

:::{.cols}
:::{.column width = "20%"}
:::
:::{.column width = "50%"}
{{< embed ../notebooks/lag_figs.qmd#pp-none >}}
:::
:::{.column width = "30%"}
:::
:::

:::{.notes}
We used area under the roc curve to evaluate model performance. auroc is the probability that a randomly selected positive case will be assigned a higher probability compared to a randomly selected negative case.  Scores can range from .5  - 1, with .5 indicating a classifier with chance performance and 1 indicating a classifier with perfect performance. 
:::

## Model Performance

:::{.cols}

:::{.column width = "20%"}
:::
:::{.column width = "50%"}
{{< embed ../notebooks/lag_figs.qmd#pp-nolag >}}
:::
:::{.column width = "30%"}
:::
:::

:::{.notes}
here is the distribution of posterior probabilities for auroc for the no lag model. The median posterior probability was .90 (depicted as the vertical solid line). The Horizonatal lines depict 95% Bayesian credible interval (CI). This interval was relatively narrow and did not contain .5. 
:::


## Model Performance

:::{.cols}

:::{.column width = "20%"}
:::
:::{.column width = "50%"}
{{< embed ../notebooks/lag_figs.qmd#pp >}}
:::
:::{.column width = "30%"}

:::{.fragment}
<span style="font-size: 25px;">Median auROC difference:</span>	   

<span style="font-size: 25px;">0.063	[0.053, 0.073]</span>   	

<span style="font-size: 25px;">Probability that models differ = 1</span>
:::
:::

:::

:::{.notes}
Here is the distribution for the two week model. Median posterior probability for auroc was .84. 

The median difference in posterior probability for these two models was .06, and there was a 1.0 probability that the lagged model performed worse than the no lag model. However, auROCs of .8 and higher are generally considered to indicate good performance. 
:::


## Feature Importance

:::{.cols}
:::{.column width = "50%"}
{{< embed ../notebooks/lag_figs.qmd#global >}}
:::

:::{.column width = "50%"}

:::
:::

:::{.notes}
We can use feature importance to contextualize model performance. 

Global feature importance is an indicator of how important a feature category was to the model’s predictions, on average (i.e., across all participants and all observations).

This plot displays the global importance for feature categories for the no lag and 2-week lag models. Feature categories are ordered by their aggregate global importance. The importance of each feature category for each model is displayed separately by color. 

The relative ordering of important features remained somewhat consistent across the two models. Past use, future efficacy, and craving were the top three features for both models. However the magnitude of their importance varried somewhat. Additionally, for the two-week model future risky situations emerged as an important feature, whereas with the no lag model past stressful events were more important.

:::

## Feature Importance

:::{.cols}
:::{.column width = "50%"}
{{< embed ../notebooks/lag_figs.qmd#global >}}
:::

:::{.column width = "50%"}
{{< embed ../notebooks/lag_figs.qmd#local >}}
:::
:::

:::{.notes}

Local feature importance is an indicator of how important a feature category is at a specific prediction timepoint (i.e., for a single individual at a single moment in time). Local importance can be used to map feature categories onto clinical interventions and recommendations (e.g., What does this individual need right now?). 

The figure on the right shows the range of local feature importance for each EMA feature category for the no lag and 2-week lag models. This plot suggests that even feature categories with low global importance (e.g., past pleasant event) have a wide range of local importance values, suggesting that for seem people at some moments these features are clinically important.
:::

## Model Fairness

:::{.fragment}

:::{.cols}
:::{.column width = "33%"}
{{< embed ../notebooks/lag_figs.qmd#pp-dem-no-lag-sex >}}
:::

:::{.column width = "33%"}

{{< embed ../notebooks/lag_figs.qmd#pp-dem-no-lag-race >}}
:::

:::{.column width = "33%"}

{{< embed ../notebooks/lag_figs.qmd#pp-dem-no-lag-income >}}
:::
:::
:::

:::{.notes}

In this study we also looked at how fair our models were for three dichotomized demographic groups with known disparities in access to substance use treatment and substance use outcomes – sex at birth (female vs. male), race and ethnicity (not White vs. non-Hispanic White), and income (below poverty vs. above poverty).

Our models performed  worse for participants who were not white and had an income below the federal poverty line. 

The largest contributing factor is likely the lack of diversity in our training data.

Even with our coarse dichotomous grouping of race we only had 20 participants in the not White group. We also saw a similar pattern in our income groups.

In just a moment I'm going to return to this issue and discuss what we are currently doing to address this.

We did however have equal representation of men and women, and we still saw differences in performance. We are not sure exactly why this is. We did choose our EMA items based on domain expertise and years of relapse risk research. It is possible that these constructs more precisely describe relapse risk factors for men than for women. This could mean that more research is needed to identify relapse risk factors for women (and other groups underrepresented in the literature more broadly).

:::

## Model Fairness

:::{.cols}
:::{.column width = "33%"}
{{< embed ../notebooks/lag_figs.qmd#pp-dem-lag-sex >}}
:::

:::{.column width = "33%"}

{{< embed ../notebooks/lag_figs.qmd#pp-dem-lag-race >}}
:::

:::{.column width = "33%"}

{{< embed ../notebooks/lag_figs.qmd#pp-dem-lag-income >}}
:::
:::

:::{.notes}
And we saw this pattern with the lagged model as well.
:::

## Conclusions

- We can achieve clinically meaningful performance up to 2 weeks out

:::{.fragment}
- Advanced notice for treatment supports that are not immediately available
:::

:::{.fragment}
- A more representative training sample is critical for developing fair models
:::

:::{.notes}
In conclusion, Our models performed exceptionally well with median posterior probabilities for auROCs of .84 - .90. This suggests we can achieve clinically meaningful performance up to two weeks out. 

Model performance did decrease when prediction windows were shifted further into the future. This is not surprising given what we know about prediction and alcohol use. Many important relapse risk factors are fluctuating processes that can change day-by-day, if not more frequently. So when looking 2-weeks out, features are less proximal to the prediction time point. Still, the benefit of advanced notice of relapse risk likely outweighs the cost to performance.

Finally, these models are not yet clinically implementable. The most notable flaw being the unfairness of model performance for non-majority groups.
:::

## Current Future Directions

- Collecting data from a more diverse sample of individuals with alcohol use disorder to improve our models

:::{.notes}
This is the first thing we are working to address in current future directions.

We are in the process of collecting data from a more diverse sample of individuals with alcohol use disorder to improve our models. And we are optimistic about this.

In EMA models from our lab that predict opioid lapses we have found that an adequately diverse sample resulted in comparative performance across these same groups.
:::



## Current Future Directions

- Delivering risk-relevant feedback



:::{.fragment}
![](https://github.com/KendraPaquette/presentations/blob/main/images/bubble_1.png?raw=true){.absolute left=100 width=22%}
:::

:::{.fragment}
![](https://github.com/KendraPaquette/presentations/blob/main/images/bubble_2.png?raw=true){.absolute left=200 bottom=20 width=35%}
:::

:::{.fragment}
![](https://github.com/KendraPaquette/presentations/blob/main/images/bubble_3.png?raw=true){.absolute right=200 width=30%}
:::

:::{.fragment}
![](https://github.com/KendraPaquette/presentations/blob/main/images/bubble_4.png?raw=true){.absolute right=20 bottom=20 width=30%}
:::

::: {.notes}

Returning again to the idea that these models will be most effective embedded in a recovery monitoring and support system.  

One crucial step is to investigate how to communicate information from our model output to individuals. Our models give us predicted probabilities of a lapse. One option would be to create thresholds for what constitutes low, medium, or high risk and relay this information to the individual. 

Another option would be to anchor the predicted probability to the individual. For example, is their risk higher or lower compared to the previous week.

But another thing our model's give us are the most important features driving that lapse prediction. We could imagine contextualizing lapse risk by alerting individuals to the most important predictor of their risk or using domain expertise to provide specific recommendations for recovery engagement. In a recently funded grant in our lab, we plan to look what combination of risk-relevant information lead to optimal engagement and clinical recovery outcomes. 
:::

## Current Future Directions

- Delivering risk-relevant feedback

- Predictions with longer lag times

![](https://github.com/KendraPaquette/presentations/blob/main/images/plan.png?raw=true){.absolute right=10 bottom=10 height=40%}


:::{.notes}
In such a system, we can imagine that even longer lags (i.e., more advanced warning) could be helpful. In the present study, we were limited by how much time we could lag predictions. If you remember participants only provided EMA for up to three months. This means data from 2 out of the 12 possible weeks is not being used for predictions. This loss of data could be one reason we saw a decrease in model performance. 
:::

## Current Future Directions

- Delivering risk-relevant feedback

- Predictions with longer lag times

- Combine EMA with other digital data (e.g., geolocation) to increase the number of model features for personalized recommendations.

![](https://github.com/KendraPaquette/presentations/blob/main/images/phones.png?raw=true){.absolute right=400 bottom=10}

:::{.notes}
Finally, we have begun to build models that combing EMA with data from other lower burden sensing methods, like geolocation and cellular communications. Including these types of digital data could increase the number of features for better personalization of support recommendations without increasing burden.
:::

## Acknowledgements

:::{.columns}

:::{.column width = "5%"}

:::

:::{.column width = "45%"}
Contributors:  

- John J. Curtin, PI
- Gaylen Fronk
- Jiachen Yu
- Sarah Sant'Ana
- Claire Punturieri
- Susan Wanta
- Madison Herrmann
- Colin Maggard
:::

:::{.column width = "45%"}
<span style="font-size: 30px;">This research was supported by NIAAA R01 AA024391 to John J. Curtin</span>


![](https://github.com/KendraPaquette/presentations/blob/main/images/qr.png?raw=true){.absolute right=300 bottom=200 height=30%}

:::

:::{.column width = "5%"}

:::

:::

:::{.notes}
I would like to thank all of the people in my lab who have made contributions to the research presented today. 

The QR code on the screen links to our study website where we have made the manuscript and all annotated analysis scripts available.

I'm happy to answer any questions now.
:::
